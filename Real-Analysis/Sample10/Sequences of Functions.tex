\documentclass{article}
\usepackage{graphicx} % Required for inserting images
\usepackage[utf8]{inputenc}
\usepackage{setspace}
\usepackage[margin=1.5cm]{geometry}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amsfonts}
\usepackage{indentfirst}

\title{Sequences of Functions}
\author{Matthew Seguin}
\date{}

\begin{document}

\maketitle

\section*{6.2.5}
\begin{center}
    \doublespacing
    Let $(f_n)$ be a sequence of functions on a common domain $A$.
    \break
    \\Assume $(f_n)$ converges uniformly on $A$ to $f$.
    \\Then for all $\delta > 0$ there exists an $N\in\mathbb{N}$ such that $|f_n (x) - f(x)| <\delta$ whenever $x\in A$ and $n\geq N$.
    \\Let $\epsilon > 0$ and let $\alpha =\epsilon / 2$ then let $N$ be so that for any $k\geq N$ we have $|f_k (x) - f(x)| <\alpha$ for all $x\in A$.
    \\So for $m, n\geq N$ we have $|f_m (x) - f_n(x)| = |f_m (x) - f(x) + f(x) - f_n(x)|\leq |f_m (x) - f(x)| + |f_n (x) - f(x)| < 2\alpha =\epsilon$.
    \\This was for arbitrary $x\in A$ and is therefore true for all $x\in A$.
    \\Similarly this was for all $\epsilon > 0$ and is therefore true for all $\epsilon > 0$.
    \\So for all $\epsilon > 0$ there exists an $N\in\mathbb{N}$ such that when $m, n\geq N$ and $x\in A$ we have $|f_m (x) - f_n (x)| <\epsilon$.
    \break
    \\Now assume that for all $\delta > 0$ there exists an $N\in\mathbb{N}$ such that when $m, n\geq N$ and $x\in A$ we have $|f_m (x) - f_n (x)| <\delta$.
    \\Note that this $N$ does not depend on $x$ but rather only depends on $\delta$.
    \\Then for each $x\in A$ we have that $(f_n (x))$ is Cauchy and therefore converges to some $y\in\mathbb{R}$.
    \\So define the function $f$ so that for each $x\in A$, $f(x)$ is the value that $(f_n (x))$ converges to.
    \\Let $\epsilon > 0$ and let $\alpha =\epsilon / 2$. Then let $N_1\in\mathbb{N}$ be such that $|f_n (x) - f_m (x)| <\alpha$ whenever $m, n\geq N_1$ and $x\in A$.
    \\For $x\in A$ let $N_2\in\mathbb{N}$ be such that $|f_m (x) - f(x)| <\alpha$ for $m\geq N_2$.
    \\This is possible because $(f_m (x))$ is Cauchy for all $x\in A$.
    \\Let $x\in A$, $n\geq N_1$, and $m\geq max\{N_1, N_2\}$.
    \\Then we have that $|f_n (x) - f(x)| = |f_n (x) - f_m (x) + f_m (x) - f(x)|\leq |f_n (x) - f_m (x)| + |f_m (x) - f(x)| < 2\alpha =\epsilon$.
    \\This was for arbitrary $x\in A$ and is therefore true for all $x\in A$.
    \\Note that here we are using $n\geq N_1$ which does not depend on $x$.
    \\While $N_2$ and therefore $max\{N_1, N_2\}$ might depend on $x$ we are only using it when introducing a new term and not in our original expression $|f_n (x) - f(x)|$.
    \\So for all $\epsilon > 0$ we have found an $N = N_1$ such that when $n\geq N$ and $x\in A$ it follows that $|f_n (x) - f(x)| <\epsilon$.
    \\Therefore $(f_n)\rightarrow f$ uniformly on $A$.
    \break
    \\So $(f_n)\rightarrow f$ uniformly on $A$ if and only if for all $\epsilon > 0$ there exists an $N\in\mathbb{N}$ such that when $m, n\geq N$ and $x\in A$ we have $|f_m (x) - f_n (x)| <\epsilon$ \qedsymbol
\end{center}


\newpage
\section*{6.2.7}
\begin{center}
    \doublespacing
    Let $f$ be uniformly continuous on $\mathbb{R}$ and let $f_n (x) = f(x +\frac{1}{n})$.
    \\Then for all $\alpha > 0$ there exists a $\delta > 0$ such that $|x - y| <\delta$ implies $|f(x) - f(y)| <\alpha$.
    \\So let $\epsilon > 0$ then let $\delta$ be such that $|x - y| <\delta$ implies $|f(x) - f(y)| <\epsilon$, and let $N\in\mathbb{N}$ be such that $\frac{1}{N} <\delta$.
    \\Such an $N$ exists by the Archimedean property.
    \\Then for $n\geq N$ we have $|x +\frac{1}{n} - x| = |\frac{1}{n}| =\frac{1}{n} <\delta$ and this implies $|f(x +\frac{1}{n}) - f(x)| = |f_n (x) - f(x)| <\epsilon$.
    \\This was for arbitrary $x\in\mathbb{R}$ and is therefore true for all $x\in\mathbb{R}$.
    \\So for all $\epsilon > 0$ we have found an $N\in\mathbb{N}$ such that when $n\geq N$ and $x\in\mathbb{R}$ we have $|f_n (x) - f(x)| <\epsilon$.
    \\So $(f_n)\rightarrow f$ uniformly on $\mathbb{R}$.
    \break
    \\If we were only given that $f$ was continuous on $\mathbb{R}$ the $\delta$ could depend on both $\epsilon$ and the point of continuity.
    \\So we would not be able to guarantee the existence of a uniform $N$ for $|f_n (x) - f(x)|$ that works for all $x\in\mathbb{R}$.
    \break
    \\For an example take $f(x) = x^2$ which we have seen previously is continuous on $\mathbb{R}$.
    \\We have $f_n (x) = f(x +\frac{1}{n}) = (x +\frac{1}{n})^2 = x^2 +\frac{2x}{n} +\frac{1}{n^2}$.
    \\So we have $|f_n (x) - f(x)| = |\frac{2x}{n} +\frac{1}{n^2}| =\frac{1}{n} |2x +\frac{1}{n}|$.
    \\Since $f$ has its domain as all of $\mathbb{R}$ the $2x$ term is unbounded so for $\epsilon > 0$ you can not find an $N\in\mathbb{N}$ such that when $n\geq N$ and $x\in\mathbb{R}$ we have $|f_n (x) - f(x)| =\frac{1}{n} |2x +\frac{1}{n}| <\epsilon$ simply because you can always choose $x$ large enough so that this inequality doesn't hold.
\end{center}


\newpage
\section*{6.3.2}
\begin{center}
    \doublespacing
    Let $h_n (x) =\sqrt{x^2 +\frac{1}{n}}$.
\end{center}

{\Large\textbf{a.}}
\begin{center}
    \doublespacing
    Simply taking the limit we get $lim_{n\rightarrow\infty } h_n (x) = lim_{n\rightarrow\infty }\sqrt{x^2 +\frac{1}{n}} =\sqrt{x^2} =|x|$.
    \\Now proving this is the limit and that convergence is uniform:
    \\We have seen previously that $\sqrt{y}$ is uniformly continuous on $[0,\infty )$.
    \\So for all $\alpha > 0$ there exists a $\delta > 0$ such that $|x - y| <\delta$ implies $|\sqrt{x} -\sqrt{y}| <\alpha$ when $x, y\in [0,\infty )$.
    \\Let $\epsilon > 0$ and let $\delta$ be such that $|x - y| <\delta$ implies $|\sqrt{x} -\sqrt{y}| <\epsilon$. Then let $N\in\mathbb{N}$ be so that $\frac{1}{N} <\delta$.
    \\Such an $N$ exists by the Archimedean property.
    \\Note that $x^2\geq 0$ for all $x\in\mathbb{R}$ and $\frac{1}{m} > 0$ for all $m\in\mathbb{N}$, so $x^2 +\frac{1}{n}\in (0,\infty )\subset [0,\infty )$ for all $x\in\mathbb{R}$ and all $n\in\mathbb{N}$.
    \\Also $x^2\in [0,\infty )$ for all $x\in\mathbb{R}$.
    \\Then for $n\geq N$ we have $|x^2 +\frac{1}{n} - x^2| = |\frac{1}{n}| =\frac{1}{n}\leq\frac{1}{N} <\delta$.
    \\This implies $|h_n (x) - h(x)| = |\sqrt{x^2 +\frac{1}{n}} -\sqrt{x^2}| <\epsilon$ whenever $n\geq N$ and $x\in\mathbb{R}$.
    \\This was for arbitrary $\epsilon > 0$ and is therefore true for all $\epsilon > 0$.
    \\So $(h_n (x))\rightarrow |x|$ uniformly \qedsymbol
\end{center}

{\Large\textbf{b.}} We know $h_n' (x) =(\frac{1}{2\sqrt{x^2 +\frac{1}{n}}})(2x) =\frac{x}{\sqrt{x^2 +\frac{1}{n}}}$ by using the algebraic differentiability theorem.
\begin{center}
    \doublespacing
    Fix some $x\in\mathbb{R}$ then $(h_n '(x))$ is a sequence of real numbers.
    \\If $x = 0$ then $(h_n '(x)) = (\frac{0}{\sqrt{0 +\frac{1}{n}}}) = (0)\rightarrow 0$ clearly.
    \\Otherwise $(x)\rightarrow x\neq 0$ and we have seen from part a that $(\sqrt{x^2 +\frac{1}{n}})\rightarrow |x|\neq 0$.
    \\Since each of these is a sequence of real numbers we have by the algebraic limit theorem that $(h_n '(x))\rightarrow\frac{x}{|x|}$ for $x\neq 0$.
    \\So for $x\in\mathbb{R}$ if $x < 0$ then $(h_n '(x))\rightarrow -1$, if $x = 0$ then $(h_n '(x))\rightarrow 0$, and if $x > 0$ then $(h_n '(x))\rightarrow 1$.
    \\So $(h_n '(x))$ converges for all $x\in\mathbb{R}$ and therefore $(h_n '(x))\rightarrow g(x)$ pointwise, where $g(0) = 0$, $g(x) = -1$ for $x < 0$, and $g(x) = 1$ for $x > 0$.
    \break
    \\However this convergence can not be uniform for any neighborhood of 0 because if it was this would imply that the limit of $(h_n)$ is differentiable at 0, but we know that the limit is $|x|$ which is not differentiable at 0 so the convergence of $(h_n ')$ can not be uniform.
\end{center}


\newpage
\section*{6.3.5}
\begin{center}
    \doublespacing
    Let $g_n (x) =\frac{nx +x^2}{2n} =\frac{x}{2} +\frac{x^2}{2n}$ for $n\in\mathbb{N}$.
\end{center}

{\Large\textbf{a.}} Simply taking the limit we get $lim_{n\rightarrow\infty } g_n (x) = lim_{n\rightarrow\infty } \frac{x}{2} +\frac{x^2}{2n} =\frac{x}{2}$.
\begin{center}
    \doublespacing
    This is the pointwise limit and works because of the following:
    \\Consider any point $x\in\mathbb{R}$ then $(g_n (x)) =(\frac{x}{2} +\frac{x^2}{2n})$. Clearly $(\frac{x}{2})\rightarrow\frac{x}{2}$ since $x$ is a fixed constant. We also know $(\frac{1}{n})\rightarrow 0$ so by the algebraic limit theorem $(\frac{x^2}{2n})\rightarrow 0$. So by the algebraic limit theorem $(g_n (x))\rightarrow\frac{x}{2}$.
    \\We have seen that $x$ is differentiable on $\mathbb{R}$ so $lim_{n\rightarrow\infty } g_n (x) = g(x) =\frac{x}{2}$ is differentiable on $\mathbb{R}$ by the algebraic differentiability theorem and $g' (x) =\frac{1}{2}$.
\end{center}

{\Large\textbf{b.}} For each $n\in\mathbb{N}$ we get $g_n '(x) =\frac{1}{2} +\frac{2x}{2n} =\frac{1}{2} +\frac{x}{n}$.
\begin{center}
    \doublespacing
    Let $M > 0$, $\epsilon > 0$, and $N >\frac{M}{\epsilon}$, such an $N\in\mathbb{N}$ exists since $\epsilon\neq 0$ and $\mathbb{N}$ is unbounded.
    \\Then for $n\geq N$ and $x\in [-M, M]$ we have $|g_n (x) -\frac{1}{2}| = |\frac{1}{2} +\frac{x}{n} -\frac{1}{2}| = |\frac{x}{n}| =\frac{|x|}{n}\leq\frac{M}{n}\leq\frac{M}{N} <\frac{M}{M /\epsilon} =\epsilon$.
    \\This was for arbitrary $x\in [-M, M]$ and is therefore true for all $x\in [-M, M]$. So $(g_n ')\rightarrow\frac{1}{2}$ uniformly on $[-M, M]$.
    \\This was also for arbitrary $M > 0$ and is therefore true for all $M > 0$ so $(g_n ')\rightarrow\frac{1}{2}$ uniformly on every interval $[-M, M]$.
    \\We have already seen in part a that $(g_n (x))$ converges for every $x\in\mathbb{R}$ so there exists an $x_0\in\mathbb{R}$ such that $(g_n (x_0))$ converges and therefore $(g_n (x))\rightarrow g(x) =\frac{x}{2}$ uniformly on every interval $[-M, M]$ and therefore on $\mathbb{R}$. Furthermore $(g_n ')\rightarrow g'$, all of this is by theorem 6.3.3 in the book that is mentioned in the problem.
\end{center}

{\Large\textbf{c.}} Let $f_n (x) =\frac{nx^2 + 1}{2n + x} =\frac{x^2 + \frac{1}{n}}{2 + \frac{x}{n}}$ for $n\in\mathbb{N}$.
\begin{center}
    \doublespacing
    First we want to compute the pointwise limit of $(f_n)$ so let $x\in\mathbb{R}$.
    \\Then by the algebraic limit theorem we know $(\frac{x}{n})\rightarrow 0$, and so $(2 +\frac{x}{n})\rightarrow 2$.
    \\We also know by the algebraic limit theorem that $(x^2 +\frac{1}{n})\rightarrow x^2$, and so $(f_n (x)) = (\frac{x^2 + \frac{1}{n}}{2 + \frac{x}{n}})\rightarrow\frac{x^2}{2} = f(x)$.
    \\So $f'(x) =\frac{2x}{2} = x$
    \\For each $n\in\mathbb{N}$ we have $f_n ' (x) =\frac{(2nx)(2n + x) - (1)(nx^2 + 1)}{(2n + x)^2} =\frac{4n^2 x + 2nx^2 - nx^2 - 1}{4n^2 + 4nx + x^2} =\frac{nx^2 + 4n^2 x - 1}{x^2 + 4nx + 4n^2}$.
    \\Let $M > 0$ and $\epsilon > 0$. Then for $x\in [-M, M]$ we have the following:
    \\$x^2 + 4nx + 4n^2 = (x + 2n)^2\geq 0$ so $|x^2 + 4nx + 4n^2| = x^2 + 4nx + 4n^2$.
    \\Also note that $x + M\geq 0$ so $4n(x + M)\geq 0$ and $x^2 + 4n(x + M)\geq 0$ since $x^2\geq 0$.
    \\So $x^2 + 4n(x + M) + 4n^2\geq 4n^2$ and therefore $x^2 + 4nx + 4n^2\geq 4n^2 - 4nM$. \\Then by letting $n > M$ we have $x^2 + 4nx + 4n^2\geq 4n^2 - 4nM > 0$. So $0 <\frac{1}{x^2 + 4nx + 4n^2}\leq\frac{1}{4n^2 - 4nM}$.
    \\And so $|f_n '(x) - x| = |\frac{nx^2 + 4n^2 x - 1}{x^2 + 4nx + 4n^2} - x| = |\frac{nx^2 + 4n^2 x - 1 - x(x^2 + 4nx + 4n^2)}{x^2 + 4nx + 4n^2}| = |\frac{nx^2 + 4n^2 x - 1 - x^3 - 4nx^2 - 4n^2 x}{x^2 + 4nx + 4n^2}| = |\frac{-1(x^3 + 3nx^2 + 1)}{x^2 + 4nx + 4n^2}| = |\frac{x^3 + 3nx^2 + 1}{x^2 + 4nx + 4n^2}|\leq |\frac{x^3}{x^2 + 4nx + 4n^2}| + |\frac{3nx^2}{x^2 + 4nx + 4n^2}| + |\frac{1}{x^2 + 4nx + 4n^2}| =\frac{|x|^3}{x^2 + 4nx + 4n^2} + \frac{3n|x|^2}{x^2 + 4nx + 4n^2} + \frac{1}{x^2 + 4nx + 4n^2}\leq\frac{M^3}{x^2 + 4nx + 4n^2} + \frac{3nM^2}{x^2 + 4nx + 4n^2} + \frac{1}{x^2 + 4nx + 4n^2} =\frac{M^3 + 3nM^2 + 1}{x^2 + 4nx + 4n^2}\leq\frac{M^3 + 3nM^2 + 1}{4n^2 - 4nM} =\frac{\frac{M^3}{n} + 3M^2 +\frac{1}{n}}{4n - 4M}$ which clearly approaches 0 as $n\rightarrow\infty$ because the denominator gets arbitrarily large while the numerator gets arbitrarily close to $3M^2$, a constant.
    \\Since this doesn't depend on $x$ we can choose an $N$ large enough so that for $n\geq N$ and $x\in [-M, M]$ we have $|f_n '(x) - x| <\epsilon$ so $(f_n '(x))\rightarrow x$ uniformly on every interval $[-M, M]$ and therefore on $\mathbb{R}$.
    \\So again by theorem 6.3.3 $(f_n (x))\rightarrow f(x) =\frac{x^2}{2}$ uniformly and $(f_n '(x))\rightarrow f'(x) = x$.
\end{center}


\newpage
\section*{6.3.6}

{\Large\textbf{a.}}
\begin{center}
    \doublespacing
    From section 5.4 let $h(x) = |x|$ for $x\in [-1, 1]$ and $h(x + 2) = h(x)$ extending $h$ to all of $\mathbb{R}$ and take $g(x) =\sum _{n=0}^\infty\frac{1}{2^n} h(2^n x)$, this section showed that this function is nowhere differentiable. Furthermore this function is bounded uniformly for all $x\in\mathbb{R}$ because $g(x + 2) = g(x)$ by the nature of $h(x)$ and $g$ is continuous on $[-1, 1]$ and therefore the range of $g$ on $[-1, 1]$ is also compact and hence bounded, so $g$ is bounded on uniformly on all of $\mathbb{R}$.
    \\So define $(f_n (x)) = (\frac{g(x)}{n})$ then for each $n\in\mathbb{N}$ we have $f_n$ is nowhere differentiable, however since $g$ is bounded we get $(f_n (x))\rightarrow 0$ which is clearly everywhere differentiable.
    \\So this is such an example of a sequence of nowhere differentiable functions that converge to an everywhere differentiable function.
\end{center}

{\Large\textbf{b.}} For $n\in\mathbb{N}$ let $f_n (x) = n$.
\begin{center}
    \doublespacing
    Clearly $f_n (x)$ does not converge for any $x\in\mathbb{R}$ since the sequence $(n)$ is unbounded and therefore can not converge.
    \\However for any fixed $n\in\mathbb{N}$ we have $f_n '(x) = 0$.
    \\Letting $\epsilon > 0$ and $N = 1$ we get for all $n\geq 1$ and therefore for all $n\in\mathbb{N}$ when $x\in\mathbb{R}$ we have $|f_n '(x) - 0| = |0 - 0| = 0 <\epsilon$.
    \\So $(f_n '(x))\rightarrow 0$ uniformly but $f_n (x)$ does not converge for any $x\in\mathbb{R}$.
\end{center}

{\Large\textbf{c.}} This is not possible, let $(f_n)$ be a sequence of functions defined on $A$ such that $(f_n)$ and $(f_n ')$ converge uniformly.
\begin{center}
    \doublespacing
    Then we have that $(f_n ')\rightarrow g$ uniformly for some function $g$.
    \\Furthermore there exists an $x_0\in A$ such that $(f_n (x_0))$ converges since $(f_n)$ converges uniformly and therefore converges pointwise for all $x\in A$.
    \\This implies that $(f_n)\rightarrow f$ uniformly for some function $f$ (this we already knew) but this also implies that $f$ is differentiable on $A$ and $f' = g$ via the theorems in section 6.3.
\end{center}

\end{document}
